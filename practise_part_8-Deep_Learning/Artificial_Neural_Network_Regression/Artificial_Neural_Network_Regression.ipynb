{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "connected-subsection",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "announced-oxygen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-berlin",
   "metadata": {},
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "amateur-myrtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_excel(\"./Folds5x2_pp.xlsx\")\n",
    "independent = dataset.iloc[ : , : -1].values\n",
    "dependent = dataset.iloc[ : , -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-auckland",
   "metadata": {},
   "source": [
    "# Spllitting Daraset Into Test Set And Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wireless-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "independent_train, independent_test, dependent_train, dependent_test = train_test_split(independent, dependent, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-enforcement",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "automated-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar_inde = StandardScaler()\n",
    "scalar_depe = StandardScaler()\n",
    "independent_train_scal = scalar_inde.fit_transform(independent_train)\n",
    "independent_test_scal = scalar_inde.transform(independent_test)\n",
    "dependent_train_scal = scalar_depe.fit_transform(dependent_train.reshape(len(dependent_train), 1))\n",
    "dependent_test_scal = scalar_depe.transform(dependent_test.reshape(len(dependent_test), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-canada",
   "metadata": {},
   "source": [
    "# Build ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-present",
   "metadata": {},
   "source": [
    "(1) Initializing ANN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "elementary-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-passage",
   "metadata": {},
   "source": [
    "(2) Adding First Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baking-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units = 6, activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-lying",
   "metadata": {},
   "source": [
    "(3) Adding Another Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "incorporate-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units = 6, activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-printer",
   "metadata": {},
   "source": [
    "(4) Adding Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "foster-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-strengthening",
   "metadata": {},
   "source": [
    "# Training ANN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-animal",
   "metadata": {},
   "source": [
    "(1) Compiling ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "quantitative-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = \"adam\", loss = \"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-dubai",
   "metadata": {},
   "source": [
    "(2) Train ANN Model On Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "great-default",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "240/240 [==============================] - 1s 1ms/step - loss: 143256.0064\n",
      "Epoch 2/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 1822.3038\n",
      "Epoch 3/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 183.8902\n",
      "Epoch 4/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 178.5029\n",
      "Epoch 5/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 175.1302\n",
      "Epoch 6/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 174.4734\n",
      "Epoch 7/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 163.0000\n",
      "Epoch 8/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 158.6344\n",
      "Epoch 9/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 149.3294\n",
      "Epoch 10/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 145.9722\n",
      "Epoch 11/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 133.6657\n",
      "Epoch 12/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 124.9265\n",
      "Epoch 13/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 115.2799\n",
      "Epoch 14/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 100.9335\n",
      "Epoch 15/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 97.3847\n",
      "Epoch 16/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 84.5746\n",
      "Epoch 17/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 76.2830\n",
      "Epoch 18/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 67.5868\n",
      "Epoch 19/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 59.9434\n",
      "Epoch 20/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 54.5609\n",
      "Epoch 21/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 49.1567\n",
      "Epoch 22/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 45.4889\n",
      "Epoch 23/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 41.4562\n",
      "Epoch 24/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 38.7381\n",
      "Epoch 25/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 36.4422\n",
      "Epoch 26/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 37.1566\n",
      "Epoch 27/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 35.5465\n",
      "Epoch 28/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 34.4554\n",
      "Epoch 29/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 34.4319\n",
      "Epoch 30/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 34.2554\n",
      "Epoch 31/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 33.1448\n",
      "Epoch 32/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 32.5752\n",
      "Epoch 33/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 31.6930: 0s - los\n",
      "Epoch 34/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 32.5616\n",
      "Epoch 35/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 32.5526\n",
      "Epoch 36/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 32.0017\n",
      "Epoch 37/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 30.8906\n",
      "Epoch 38/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 29.2064\n",
      "Epoch 39/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 30.4936\n",
      "Epoch 40/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 30.4198\n",
      "Epoch 41/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 29.6514\n",
      "Epoch 42/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 29.7670\n",
      "Epoch 43/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 29.1819\n",
      "Epoch 44/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 29.7800\n",
      "Epoch 45/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 29.4794\n",
      "Epoch 46/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 28.0681\n",
      "Epoch 47/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 27.8811\n",
      "Epoch 48/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 29.7532\n",
      "Epoch 49/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 28.5921\n",
      "Epoch 50/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 28.0931\n",
      "Epoch 51/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.0967\n",
      "Epoch 52/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.1023\n",
      "Epoch 53/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.3190\n",
      "Epoch 54/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 27.9170\n",
      "Epoch 55/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 28.1004\n",
      "Epoch 56/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.0428\n",
      "Epoch 57/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.1752\n",
      "Epoch 58/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.4149\n",
      "Epoch 59/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.6128\n",
      "Epoch 60/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.1939\n",
      "Epoch 61/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.5271\n",
      "Epoch 62/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.1819\n",
      "Epoch 63/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.8814\n",
      "Epoch 64/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.3524\n",
      "Epoch 65/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.4632\n",
      "Epoch 66/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.6328\n",
      "Epoch 67/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.1987\n",
      "Epoch 68/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.0021\n",
      "Epoch 69/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.8154\n",
      "Epoch 70/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 25.6299\n",
      "Epoch 71/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.4208\n",
      "Epoch 72/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.6288\n",
      "Epoch 73/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.4358\n",
      "Epoch 74/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.4824\n",
      "Epoch 75/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 25.2229\n",
      "Epoch 76/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.1368\n",
      "Epoch 77/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.8023\n",
      "Epoch 78/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.1162\n",
      "Epoch 79/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.2905\n",
      "Epoch 80/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.2600\n",
      "Epoch 81/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.0948\n",
      "Epoch 82/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.1996\n",
      "Epoch 83/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.2865\n",
      "Epoch 84/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.5406\n",
      "Epoch 85/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 28.0458\n",
      "Epoch 86/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.0195\n",
      "Epoch 87/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 25.7250\n",
      "Epoch 88/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.0384\n",
      "Epoch 89/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.0146\n",
      "Epoch 90/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 25.8318\n",
      "Epoch 91/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 28.1774\n",
      "Epoch 92/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.5455\n",
      "Epoch 93/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.9797: 0s - loss: 27.\n",
      "Epoch 94/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 25.8017\n",
      "Epoch 95/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.5395\n",
      "Epoch 96/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.3606\n",
      "Epoch 97/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.9493\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 0s 1ms/step - loss: 26.6906\n",
      "Epoch 99/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.0752\n",
      "Epoch 100/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.0128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb7de9be5e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(independent_train, dependent_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-salvation",
   "metadata": {},
   "source": [
    "# Predicting Test Set values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "plain-threshold",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_pred =   ann.predict(independent_test)\n",
    "dependent_pred = dependent_pred.reshape(-1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "atlantic-backup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[431.23      , 431.33218384],\n",
       "       [460.01      , 462.42153931],\n",
       "       [461.14      , 465.95367432],\n",
       "       ...,\n",
       "       [473.26      , 473.12680054],\n",
       "       [438.        , 440.00524902],\n",
       "       [463.28      , 459.1751709 ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack((dependent_test, dependent_pred), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-credit",
   "metadata": {},
   "source": [
    "# Making Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "future-telling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.915967471224574\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(dependent_test, dependent_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "recent-marsh",
   "metadata": {},
   "source": [
    "In this model with fearture scaling and without it both gives same accuracy so feature scaling step can be removed\n",
    "for this particular example but recomended to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-stylus",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
